#! /usr/local/bin/bash

# Run the sequence of sql and python scripts to re-create and update the cuny_curriculum database.

# LOGGING AND ERROR REPORTING
#   Progress messages are displayed on stderr and in ${update_log} for all steps, including basic
#   database manipulation steps (which used to be logged separately early in the development
#   process). If any step fails to complete normally, an email containing the log file is sent to
#   the "webmaster" and the process is aborted.
if [[ $HOSTNAME =~ trexlabs ]]
then export HOME_DIR=/home/chris
else export HOME_DIR=/Users/vickery
fi

export WEBMASTER='<Christopher Vickery> christopher.vickery@qc.cuny.edu'
export PYTHONPATH="$HOME_DIR/Projects/dgw_processor:$HOME_DIR/Projects/transfer_app/"

# send_notice()
# -------------------------------------------------------------------------------------------------
# Email the current state of the update.log file to the WEBMASTER.
#
function send_notice () {
  rm -f ./notification_report
  echo Notice from `hostname` > ./notification_report
  # for file in update*.log
  # do
  echo -e "\n--- ${update_log} ---" >> ./notification_report
  cat ${update_log} >> ./notification_report
  # done

  # sendemail must be in the PATH as a (hard) link to sendemail.py in transfer-app.
  $HOME_DIR/bin/sendemail -s "Update_db Notice: $1" -t ./notification_report "$WEBMASTER"

  rm -f ./notification_report
  echo -e "$1.\nUpdate logfile sent to $WEBMASTER."
}

(
  # Support execution from other dirs than the project directory
  cd $HOME_DIR/Projects/cuny_curriculum

  export PGOPTIONS='--client-min-messages=warning'
  #   --client-min-messages=warning to suppress NOTICE messages
  #   -X suppress reading .psqlrc (where I set timing)
  #   -f rather than < to get line numbers when a command fails
  #   -q to suppress CREATE TABLE, etc messages

  # COMMAND LINE ARGUMENTS AND ENVIRONMENT VARIABLES
  # This update_db command normally runs with no arguments, but the normal process can be modified
  # to help manual recovery from abnormalities in the processes of running CUNYfirst queries and
  # transferring the resulting .CSV files to Tumbleweed.
  #
  # Dump and restore events table. (NO LONGER USED)
  #   The update process deletes all tables in the cuny_curriculum database and then rebuilds
  #   everything based on the information in the queries that ran on CUNYfirst. But the events table
  #   comes from user input in reviewing transfer rules, not CUNYfirst, so it can't be rebuilt from
  #   CUNYfirst data. Before dropping the db, the events table is dumped to a file, and then that
  #   file is restored near the end of the update process.
  #
  #   The NO_EVENTS environment variable, the -ne, or the --no-events command line option can be
  #   used to suppress the dump restore of the dumps table.
  #
  # Archive tables that don't come from CUNYfirst. (NO LONGER USED)
  #   These have to be preserved in case they get corrupted during the actions that happen in
  #   CUNY_Programs.
  #
  # Download queries from Tumbleweed.
  #   The 21 CUNYfirst queries that are used to build the database are saved as .CSV files
  #   and transferred to Tumbleweed by the CUNYfirst query scheduling system.
  #
  #   The ./check_query.py script can be run with the -r option to see the query names and their
  #   CUNYfirst run_control ids. All queries are scheduled to run in the CUNYfirst reporting
  #   instance each Tuesday morning at 7 am.
  #
  #   The SKIP_DOWNLOAD environment variable, the -sd, or the --skip-download command line option
  #   can be used to skip the download from Tumbleweed, iconv, and move into queries steps.
  #
  # Check the integrity of the query files.
  #   Once the query files are in the queries folder, they are checked to be sure they are all
  #   there, that they were all created on the same date, that they all have non-zero sizes, and
  #   that their sizes are within 10% of the sizes of the previous versions of the files. If all
  #   goes well, the file names are normalized (by dropping the CUNYfirst process id part of the
  #   file name), copied into the query_archives folder with their creation dates replacing their
  #   CUNYfirst process id in their file names, and moved into the latest_queries folder with their
  #   process ids removed for subsequent access by the update process steps to follow.
  #
  #   NO_SIZE_CHECK -ns --no-size-check
  #   NO_DATE_CHECK -nd --no-date-check
  #   NO_ARCHIVE -na --no-archive
  #   These three can be used to suppress their respective steps.
  #
  # Update registered programs.
  #   After the cuny_curriculum database update is finished, the table of academic programs
  #   registered with the NYS Department of Education (registered_programs) takes place.
  #
  #   NO_PROGRAMS -np --no-programs
  #   Suppress the registered_programs table update.

  # Environment variables, which can be overridden by command line options
  for env_var in NO_EVENTS SKIP_DOWNLOAD NO_SIZE_CHECK NO_DATE_CHECK NO_ARCHIVE NO_PROGRAMS
  do
    if [[ `printenv` =~ $env_var ]]
    then export `echo $env_var | tr A-Z a-z`=1
    fi
  done

  # Command line option processing
  export progress=''
  export report=''
  unset progress report no_events skip_download no_size_check no_date_check no_archive no_programs
  while [ $# -gt 0 ]
  do
    if [[ ( "$1" == "--interactive" ) || ( "$1" == '-i' ) ]]
    then progress='--progress'
         report='--report'
    elif [[ ( "$1" == "--no-events" ) || ( "$1" == "-ne" ) ]]
    then no_events=true
    elif [[ ( "$1" == "--skip-download") || ( "$1" == "-sd" ) ]]
      then skip_download=true
    elif [[ ( "$1" == "--no-size-check") || ( "$1" == "-ns" ) ]]
      then no_size_check=true
    elif [[ ( "$1" == "--no-date-check") || ( "$1" == "-nd" ) ]]
      then no_date_check=true
    elif [[ ( "$1" == "--no-archive") || ( "$1" == "-na" ) ]]
      then no_archive=true
    elif [[ ( "$1" == "--no-programs" ) || ( "$1" == "-np" ) ]]
      then no_programs=true
    elif [[ ( "$1" == "--ignore-new" ) || ( "$1" == "-in" ) ]]
      then ignore_new=true
    else
      echo "Usage: $0 [-ne | --no-events] [-ns | --no-size-check] [-nd | --no-date-check]
       [-na | --no-archive] [-sd | --skip_download] [-np | --no_programs] [-i | --interactive]"
      exit 1
    fi
    shift
  done

  # # Uncomment for debugging
  # for arg in no_events skip_download no_size_check no_date_check no_archive no_programs
  # do
  #   if [[ `printenv` =~ $arg ]]
  #   then echo $arg is set
  #   else echo $arg is not set
  #   fi
  # done

  # Include path to update.log file so script can be invoked from any directory.
  export update_log=`pwd`/update.log
  truncate -s0 ${update_log}

  echo BEGIN UPDATE at `date +"%Y-%m-%d %T"` | tee -a ${update_log}
  SECONDS=0
  send_notice "Started updating database cuny_curriculum on $HOSTNAME"

  # Can't do downloads except from a cuny.edu host.
  if [[ ! ( `hostname` =~ cuny.edu ) ]]
  then echo "Cannot access Tumbleweed from `hostname`" | tee -a ${update_log}
       skip_download=true
  fi

  # Try downloading new queries
  if [[ $skip_download ]]
  then echo "SKIPPING DOWNLOADS." | tee -a ${update_log}
  else
    echo -n "DOWNLOAD new query files... " | tee -a ${update_log}
    ./get_cuny >> ${update_log}
    if [[ $? -eq 1 ]]
    then  # May want to update db with existing set of queries, but make note of it.
          send_notice "NOTE: No new query files"
    fi
    echo done. | tee -a ${update_log}
  fi

  # Python scripts process query results, so check that they are all present.
  # Report any mismatched dates, truncated or abnormally-sized queries and abort if not all a-ok

  echo -n "CHECK & ARCHIVE QUERY FILES... " | tee -a ${update_log}
  args=''
  [[ $no_size_check ]] && args="$args -ss"
  [[ $no_date_check ]] && args="$args -sd"
  [[ $no_archive ]] && args="$args -sa"
  [[ $ignore_new ]] && args="$args --ignore_new"

  ./check_queries.py $args >> ${update_log} 2>&1
  if [ $? -ne 0 ]
    then send_notice "ERROR: query checks failed"
         exit 1
    else echo "done." | tee -a ${update_log}
  fi

  # Enter update_db mode and give time for running queries to complete
  echo "START update_db mode" | tee -a ${update_log}
  redis-cli -h localhost set update_db_started `date +%s`

  # Kill any existing connections to the db
  echo -n "DROP Connections and Tables ... " | tee -a ${update_log}
  psql -X -q -d cuny_curriculum -f drop_connections.sql >> ${update_log}
  psql -X -q -d cuny_curriculum -f drop_tables.sql >> ${update_log}
  echo done. | tee -a ${update_log}

  echo -n "CREATE FUNCTIONs numeric_part and rule_key ... " | tee -a ${update_log}
  psql -X -q -d cuny_curriculum -f numeric_part.sql >> ${update_log}
  psql -X -q -d cuny_curriculum -f rule_key.sql >> ${update_log}
  echo done. | tee -a ${update_log}

  echo -n "LOAD BASE TABLES ... " | tee -a ${update_log}
  ./load_cuny_base_tables.py >> ${update_log} 2>&1
  if [[ $? -ne 0 ]]
    then send_notice 'ERROR: load_plans-subplans failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  # The following is the organizational structure of the University, showing the terminology used by
  # CUNY (in parens) as adapted (perhaps unwisely) for use in this database.
  #   There are 21 colleges at CUNY (institution). This db keeps the “institution” nomenclature.
  #   Students are undergraduate or graduate (careers) at an institution
  #   Institutions own “divisions” (academic groups), but some places call them schools, or even
  #   colleges.
  #   Divisions own “departments” (academic organizations)
  #   Departments own “disciplines” (subjects)
  #   Disciplines map to “CUNY subjects” (external subject areas)
  #   Disciplines have courses
  #   Courses have a catalog number, title, requirement designation, and attributes, and more.
  #.  Every CUNY course has a unique course_id and offer_number. Courses with the same course_id
  #.  (different offer_numbers) are said to be “cross-listed.”
  #
  # The sequence of initializations, however, does not quite follow this
  # structure:
  #   Careers references cuny_institutions, so create cuny_institutions first
  #   cuny_divisions references cuny_departments, so create cuny_departments first
  #
  echo -n "CREATE TABLE cuny_institutions... " | tee -a ${update_log}
  psql -X -q -d cuny_curriculum -f cuny_institutions.sql >> ${update_log} 2>&1
  psql -X -q -d cuny_curriculum -c "update updates \
                                    set update_date='`gdate -I -r cuny_institutions.sql`',\
                                        file_name = 'cuny_institutions.sql' \
                                    where table_name = 'cuny_institutions'"
  echo done. | tee -a ${update_log}

  echo -n "CREATE academic_programs... " | tee -a ${update_log}
  python3 cuny_programs.py >> ${update_log} 2>&1
  if [[ $? -ne 0 ]]
    then send_notice 'ERROR: cuny_programs failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  # Now regenerate the tables from the Reporting Instance query results.
  #
  echo -n "CREATE TABLE cuny_careers... " | tee -a ${update_log}
  python3 cuny_careers.py >> ${update_log} 2>&1
  if [ $? -ne 0 ]
    then send_notice 'ERROR: cuny_careers failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  echo -n "CREATE TABLE cuny_divisions... " | tee -a ${update_log}
  python3 cuny_divisions.py >> ${update_log} 2>&1
  if [ $? -ne 0 ]
    then send_notice 'ERROR: cuny_divisions failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  echo -n "CREATE TABLE cuny_departments... " | tee -a ${update_log}
  python3 cuny_departments.py >> ${update_log} 2>&1
  if [ $? -ne 0 ]
    then send_notice 'ERROR: cuny_departments failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  echo -n "CREATE TABLE cuny_subjects... " | tee -a ${update_log}
  python3 cuny_subjects.py >> ${update_log} 2>&1
  if [ $? -ne 0 ]
    then send_notice 'ERROR: cuny_subjects failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  echo -n "CREATE TABLE designations... " | tee -a ${update_log}
  python3 designations.py >> ${update_log} 2>&1
  if [ $? -ne 0 ]
    then send_notice 'ERROR: designations failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  echo -n "CREATE TABLE crse_quiv_tbl... " | tee -a ${update_log}
  python3 mk_crse_equiv_tbl.py $progress 2>> ${update_log}
  if [ $? -ne 0 ]
    then send_notice 'ERROR: mk_crse_equiv_tbl failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  echo -n "CREATE TABLE cuny_courses... " | tee -a ${update_log}
  psql -X -q -d cuny_curriculum -f create_cuny_courses.sql >> ${update_log} 2>&1
  if [ $? -ne 0 ]
    then send_notice 'ERROR: create_cuny_courses failed'
         exit 1
  fi
  echo -n "CREATE VIEW cuny_courses... " | tee -a ${update_log}
  psql -X -q -d cuny_curriculum -f view_courses.sql >> ${update_log} 2>&1
  if [ $? -ne 0 ]
    then send_notice 'ERROR: view_courses failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  echo -n "POPULATE courses... " | tee -a ${update_log}
  python3 populate_cuny_courses.py $progress 2>> ${update_log}
  if [ $? -ne 0 ]
    then send_notice 'ERROR: populate_cuny_courses failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  echo -n "CHECK component contact hours... " | tee -a ${update_log}
  python3 check_total_hours.py > check_contact_hours.log 2>&1
  if [ $? -ne 0 ]
    then send_notice 'ERROR: check_total_hours failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  # Transfer rules
  echo -n "CREATE TABLE review_status_bits... " | tee -a ${update_log}
  psql -X -q -d cuny_curriculum -f review_status_bits.sql >> ${update_log} 2>&1
  if [ $? -ne 0 ]
    then send_notice 'ERROR: review_status_bits failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  echo -n "CREATE transfer_rules, source_courses, destination_courses... " | tee -a ${update_log}
  psql -X -q -d cuny_curriculum -f create_transfer_rules.sql >> ${update_log} 2>&1
  if [ $? -ne 0 ]
    then send_notice 'ERROR: create/view transfer_rules failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  echo -n "POPULATE transfer_rules... " | tee -a ${update_log}
  python3 populate_transfer_rules.py $progress $report 2>> ${update_log}
  if [ $? -ne 0 ]
    then send_notice 'ERROR: populate_transfer_rules failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  echo -n "SPEEDUP transfer_rule lookups... " | tee -a ${update_log}
  python3 mk_subject-rule_map.py $progress >> ${update_log} 2>&1
  if [ $? -ne 0 ]
    then send_notice 'ERROR: mk_subject-rule_map failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  # Archive transfer rules
  echo "Archive transfer rules" | tee -a ${update_log}
  ./archive_rules.sh >> ${update_log} 2>&1
  echo done. | tee -a ${update_log}

  # cuny_sessions
  echo -n "RECREATE cuny_sessions table... " | tee -a ${update_log}
  ./load_sessions_table.py >> ${update_log} 2>&1
  if [ $? -ne 0 ]
    then send_notice 'ERROR: load_sessions_table failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  # class_max_term table (Not actually used)
  echo -n "CREATE class_max_term table... " | tee -a ${update_log}
  ./class_max_term.py >> ${update_log} 2>&1
  if [ $? -ne 0 ]
    then send_notice 'ERROR: class_max_term failed'
         exit 1
  fi
  echo done. | tee -a ${update_log}

  # THE T-REX IMPLEMENTATION NOW HANDLES THE RULE-REVIEW WORKFLOW, SO THE FOLLOWING STEPS ARE NO
  # LONGER DONE HERE.

  # The following takes too long, and doesn't really do more than
  # populate_transfer_rules.py already did. Historical Artifact.
  # echo -n "CHECK bogus rules... " | tee -a ${update_log}
  # python3 bogus_rules.py $progress >> ${update_log} 2>&1
  # if [ $? -ne 0 ]
  #   then send_notice 'ERROR: bogus_rules failed'
  # fi
  # echo done.

  # Managing the rule review process
  #    2019-10-5: using Flask redis sessions instead of mysession
  # echo -n "CREATE TABLE sessions... " | tee -a ${update_log}
  # psql -X -q -d cuny_curriculum -f sessions.sql >> ${update_log} 2>&1
  # if [ $? -ne 0 ]
  #   then send_notice 'ERROR: sessions failed'
  #        exit 1
  # fi
  # echo done. | tee -a ${update_log}

  # #echo CREATE TABLE pending_reviews...
  # #echo CREATE TABLE event_types...
  # echo -n "CREATE TABLE events... " | tee -a ${update_log}
  # psql -X -q -d cuny_curriculum -f reviews-events.sql >> ${update_log} 2>&1
  # if [ $? -ne 0 ]
  #   then send_notice 'ERROR: reviews-events failed'
  #        exit 1
  # fi
  # echo done. | tee -a ${update_log}

  # export EVENTS_TABLE=events-dump_`gdate +'%F_%H:%M'`.sql
  # if [[ ! $no_events ]]
  # then
  #   echo -n "RESTORE previous events from $EVENTS_TABLE ... " | tee -a ${update_log}
  #   psql -X -q -d cuny_curriculum -f $EVENTS_TABLE >> ${update_log} 2>&1
  #   if [ $? -ne 0 ]
  #     then send_notice 'ERROR: restore events_table failed'
  #          exit 1
  #   fi
  #   echo done. | tee -a ${update_log}

  #   echo ARCHIVE the events table.
  #   mv $EVENTS_TABLE ./event_dumps/

  #   echo -n "UPDATE review statuses... " | tee -a ${update_log}
  #   python3 update_review_statuses.py >> ${update_log} 2>&1
  #   if [ $? -ne 0 ]
  #     then send_notice 'ERROR: review_statuses failed'
  #          exit 1
  #   fi
  #   echo done. | tee -a ${update_log}
  # fi

  # # User roles and access
  # echo -n "Re-build the roles and person_roles tables ..." | tee -a ${update_log}
  # psql -X -q -d cuny_curriculum -f roles.sql >> ${update_log} 2>&1
  # echo done. | tee -a ${update_log}

  # echo -n "(Re-)Grant select access to view_only ROLE ..." | tee -a ${update_log}
  # psql -X -q -d cuny_curriculum -f view_only_role.sql >> ${update_log} 2>&1
  # echo done. | tee -a ${update_log}


if [[ $no_programs ]]
then
  echo "SKIPPING CUNY_Programs" | tee -a ${update_log}
else
  echo "UPDATE CUNY Programs and Requirement Blocks... " | tee -a ${update_log}
  (
    cd $HOME_DIR/Projects/cuny_programs
    ./update_registered_programs.sh | tee -a ${update_log}
    if [ $? -ne 0 ]
    then send_notice 'NOTICE: update_registered_programs.sh failed'
#         exit 1
    fi
    cd $HOME_DIR/Projects/cuny_programs/dgw_requirement_blocks
    ./update_requirement_blocks.py
    if [ $? -ne 0 ]
    then send_notice 'NOTICE: update_requitement_blocks.py failed'
 #        exit 1
    fi
  )
  echo done. | tee -a ${update_log}
fi

  # Exit update_db mode
  echo -n "END update_db mode: " | tee -a ${update_log}
  redis-cli -h localhost set update_db_started 0

  echo UPDATE COMPLETED at `date +"%Y-%m-%d %T"` in `gdate -d @"$SECONDS" +'%-Mm %-Ss'` | \
       tee -a ${update_log}
       send_notice "Finished updating database cuny_curriculum on $HOSTNAME"

  echo done. | tee -a ${update_log}
)
